# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

This data set has data of customers of a financial institution. This data set is used for a marketing campaign to identify and target customers who are likely to to start a deposit account or a term deposit account. The data set is used to predict and identify these customers and using this prediction the marketing campaign would target these customers with new deposit term accounts.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

AutoML provided the best model. The XGBoost Classifier with Standard Scaling was the best performing model with an accuracy of 0.9154.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The pipeline architecture includes 
  - Data Ingestion : The data is ingested into the Azure Blob storage and registed with the Azure ML data sets.
  - Data Preparation: Data Prepaaration involves cleaning, data imputation, one-hot encoding. This is done using a custom script.
  - Hyperameter Tuning: The choosen algorithm depends on certain hyperparameters. Hyperparameter tuning is the process of finding the best parameters for training the model for which the algorithm gives the best perfomance.
  - Classification Algorithm: Logistic Regression with regularization is choosen as the classification algorithm to perform the binary classification of the banking data set.

**What are the benefits of the parameter sampler you chose?**

Parameter Sampling or Random Parameter Sampling supports both continous and discrete hyperparameters. Random Sampling supports aarly termination of low-performance training runs.

**What are the benefits of the early stopping policy you chose?**

Early termination policy helps in the termination of poorly performing training runs. This helps in improving the computational efficiency.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The best model was votingensemble model with a lasso regularization or l1_ratio of 0.387. The advantages of l1_ratio helps in reducing overfitting and balanaces bias and variance. Learning rate or step size helps in controling in converging to the optimal solution. A very large learning rate might help the training process to converge quickly to a suboptimal solution or a very small learning rate might take a very long time to converge. Inverse Scaling is a adaptive leraning rate meachanism used by certain optimization algorithms that help converge to the optimal solution and also does not sacrifice the computational efficiency. The classification algorithm uses the log loss which is also sometimes referred as the Likelihood function which is basically how likely is the observed set of outcomes a positive class or a negative class based on the calculated probability and threshold.

The parameters of the best model obtained by the AutoML run is listed below.
fit_intercept=True,
                                                                                                  l1_ratio=0.3877551020408163,
                                                                                                  learning_rate='invscaling',
                                                                                                  loss='log',
                                                                                                  max_iter=1000,
                                                                                                  n_jobs=1,
                                                                                                  penalty='none',
                                                                                                  power_t=0,
                                                                                                  random_state=None,
                                                                                                  tol=0.01))],

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

  
  - In terms of architecture the data pipelines were similar, but the configuration defnitions for the runs AutoML was easier to setup.
  - IN terms of accuracy both the runs had similar accuracy of 0.909 for hyperdrive and 0.918 for the AutoML run
  - Hyperdrive run we could only tune hyperparameters for just one algorithm whereas AutoML tunes hyperpararmeters of various algorithms as well as chooses different algorithms to find the best model and the hyperparameters associated with the models.
  - Hyperdrive training runs are lot faster as compared to AutoML as AutoML searches acroos many algorithms and hyperparameters whereas hyperdrive searches for optimal hyperparameters for just one algorithm.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

During the AutoML run a message was output which indicated that the data set is imbalanced. In order to get better results we might have to perfomr over sampling, undersampling or perfomr SMOTE techniques on the data set in order to generate synthetic data so that we have a more balanced set to train and come up with a better performing model, as the accuracy of the cuurent trained model although high might not be identifying the miinority class very well.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
